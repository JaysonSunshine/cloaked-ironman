{
 "metadata": {
  "name": "",
  "signature": "sha256:33756715aefa46ae6ab0d0e6da9caf2ff3e8cc56198da4abb01609dbd548d183"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.context import SparkContext\n",
      "print \"Running Spark Version %s\" % (sc.version)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Running Spark Version 1.1.0\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.conf import SparkConf\n",
      "conf = SparkConf()\n",
      "print conf.toDebugString()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "spark.app.name=pyspark-shell\n",
        "spark.io.compression.codec=org.apache.spark.io.LZFCompressionCodec\n",
        "spark.master=local[*]\n",
        "spark.submit.pyFiles=\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "movies_file = sc.textFile(\"movielens/medium/movies.dat\")\n",
      "movies_rdd = movies_file.map(lambda line: line.split('::'))\n",
      "movies_rdd.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "3883"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "movies_rdd.first()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "[u'1', u'Toy Story (1995)', u\"Animation|Children's|Comedy\"]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ratings_file = sc.textFile(\"movielens/medium/ratings.dat\")\n",
      "ratings_rdd = ratings_file.map(lambda line: line.split('::'))\n",
      "ratings_rdd.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "1000209"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ratings_rdd.first()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "[u'1', u'1193', u'5', u'978300760']"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parse_ratings(x):\n",
      "    user_id = int(x[0])\n",
      "    movie_id = int(x[1])\n",
      "    rating = float(x[2])\n",
      "    timestamp = int(x[3])/10\n",
      "    return [user_id,movie_id,rating,timestamp]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ratings_rdd_01 = ratings_rdd.map(lambda x: parse_ratings(x))\n",
      "ratings_rdd_01.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "1000209"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ratings_rdd_01.first()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "[1, 1193, 5.0, 97830076]"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#numRatings = ratings_rdd_01.count()\n",
      "#numUsers = ratings_rdd_01.collect().map(lambda r: r[0]).distinct().count()\n",
      "#numMovies = ratings_rdd_01.collect().map(lambda r: r[1]).distinct().count()\n",
      "\n",
      "#print \"Got %d ratings from %d users on %d movies.\" % (numRatings, numUsers, numMovies)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training = ratings_rdd_01.filter(lambda x: (x[3] % 10) < 6)\n",
      "validation = ratings_rdd_01.filter(lambda x: (x[3] % 10) >= 6 and (x[3] % 10) < 8)\n",
      "test = ratings_rdd_01.filter(lambda x: (x[3] % 10) >= 8)\n",
      "numTraining = training.count()\n",
      "numValidation = validation.count()\n",
      "numTest = test.count()\n",
      "print \"Training: %d, validation: %d, test: %d\" % (numTraining, numValidation, numTest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training: 600069, validation: 199985, test: 200155\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.mllib.recommendation import ALS\n",
      "rank = 10\n",
      "numIterations = 20\n",
      "train_data = test.map(lambda p: (p[0], p[1], p[2]))\n",
      "model = ALS.train(train_data, rank, numIterations)\n",
      "print model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<pyspark.mllib.recommendation.MatrixFactorizationModel object at 0x10865d650>\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Evaluate the model on training data\n",
      "testdata = test.map(lambda p: (p[0], p[1]))\n",
      "predictions = model.predictAll(testdata).map(lambda r: ((r[0], r[1]), r[2]))\n",
      "predictions.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "200155"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions.first()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "((5153, 3456), 2.8954613932078992)"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testdata.first()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "(1, 2355)"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test.first()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "[1, 2355, 5.0, 97882429]"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_key_rdd = test.map(lambda r: ((r[0], r[1]), r[2]))\n",
      "print test_key_rdd.count()\n",
      "test_key_rdd.first()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "200155\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "((1, 2355), 5.0)"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ratesAndPreds = test.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
      "ratesAndPreds = test_key_rdd.join(predictions)\n",
      "ratesAndPreds.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "200155"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ratesAndPreds.first()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "((5627, 45), (4.0, 3.2888861241578016))"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).reduce(lambda x, y: x + y)/ratesAndPreds.count()\n",
      "print(\"Mean Squared Error = \" + str(MSE))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Mean Squared Error = 0.335920662655\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Advanced - to try later\n",
      "*** system will hang if it has less memory"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def computeRmse(model, data, n):\n",
      "    \"\"\"\n",
      "    Compute RMSE (Root Mean Squared Error).\n",
      "    \"\"\"\n",
      "    predictions = model.predictAll(data.map(lambda x: (x[0], x[1])))\n",
      "    predictionsAndRatings = predictions.map(lambda x: ((x[0], x[1]), x[2])) \\\n",
      "      .join(data.map(lambda x: ((x[0], x[1]), x[2]))) \\\n",
      "      .values()\n",
      "    return sqrt(predictionsAndRatings.map(lambda x: (x[0] - x[1]) ** 2).reduce(add) / float(n))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "ranks = [8, 12]\n",
      "lambdas = [1.0, 10.0]\n",
      "numIters = [10, 20]\n",
      "bestModel = None\n",
      "bestValidationRmse = float(\"inf\")\n",
      "bestRank = 0\n",
      "bestLambda = -1.0\n",
      "bestNumIter = -1\n",
      "\n",
      "for rank, lmbda, numIter in itertools.product(ranks, lambdas, numIters):\n",
      "    model = ALS.train(train_data, rank, numIter, lmbda)\n",
      "    validationRmse = computeRmse(model, validation, numValidation)\n",
      "    print \"RMSE (validation) = %f for the model trained with \" % validationRmse + \\\n",
      "          \"rank = %d, lambda = %.1f, and numIter = %d.\" % (rank, lmbda, numIter)\n",
      "    if (validationRmse < bestValidationRmse):\n",
      "        bestModel = model\n",
      "        bestValidationRmse = validationRmse\n",
      "        bestRank = rank\n",
      "        bestLambda = lmbda\n",
      "        bestNumIter = numIter\n",
      "\n",
      "testRmse = computeRmse(bestModel, test, numTest)\n",
      "\n",
      "# evaluate the best model on the test set\n",
      "print \"The best model was trained with rank = %d and lambda = %.1f, \" % (bestRank, bestLambda) \\\n",
      "  + \"and numIter = %d, and its RMSE on the test set is %f.\" % (bestNumIter, testRmse)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}